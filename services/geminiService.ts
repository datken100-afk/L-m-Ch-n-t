
import { GoogleGenAI, Type, Schema, GenerateContentResponse } from "@google/genai";
import { Difficulty, GeneratedMCQResponse, GeneratedStationResponse, MentorResponse, StationItem } from "../types";

// Storage Key for User's Custom API Key
export const STORAGE_API_KEY = 'OTTER_API_KEY';

// Helper to get the active client instance dynamically
const getAI = () => {
    const customKey = localStorage.getItem(STORAGE_API_KEY);
    // Prioritize custom key, fallback to env
    const key = customKey && customKey.trim().length > 0 ? customKey : (process.env.API_KEY || '');
    
    if (!key) {
        // Throw a specific error that UI can catch to show the Key Modal
        throw new Error("MISSING_API_KEY"); 
    }
    return new GoogleGenAI({ apiKey: key });
};

// OPTIMIZATION: Use Gemini 2.5 Flash exclusively.
const MODEL_MCQ = "gemini-2.5-flash"; 
const MODEL_VISION = "gemini-2.5-flash"; 
const MODEL_CHAT = "gemini-2.5-flash";

interface ContentFile {
    content: string;
    isText: boolean;
}

// OPTIMIZATION: Strict Token Limits.
const LIMIT_THEORY_CHARS = 60000; 
const LIMIT_CLINICAL_CHARS = 30000; 
const LIMIT_SAMPLE_CHARS = 20000;

// --- RETRY LOGIC HELPER ---
const wait = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

async function retryGeminiCall<T>(
  call: () => Promise<T>,
  retries: number = 3,
  initialDelay: number = 2000
): Promise<T> {
  let lastError: any;
  
  for (let i = 0; i < retries; i++) {
    try {
      return await call();
    } catch (error: any) {
      lastError = error;
      
      const isRateLimit = 
        error.status === 429 || 
        error.status === 503 ||
        (error.message && (
          error.message.includes("429") || 
          error.message.includes("quota") || 
          error.message.includes("RESOURCE_EXHAUSTED") ||
          error.message.includes("Overloaded")
        ));

      if (error.status === 404 || (error.message && error.message.includes("not found"))) {
          throw new Error(`L·ªói Model AI (${error.status}): Kh√¥ng t√¨m th·∫•y Model. Vui l√≤ng Redeploy code m·ªõi nh·∫•t.`);
      }
      
      // Invalid Key Error
      if (error.status === 400 && error.message?.includes("API key")) {
          throw new Error("INVALID_API_KEY");
      }

      if (isRateLimit) {
        if (i === retries - 1) break; 
        console.warn(`Gemini Rate Limit hit. Retrying in ${initialDelay}ms... (Attempt ${i + 1}/${retries})`);
        await wait(initialDelay);
        initialDelay *= 2; 
      } else {
        throw error; 
      }
    }
  }
  
  const cleanMsg = lastError?.message || "Unknown error";
  if (cleanMsg.includes("quota") || cleanMsg.includes("RESOURCE_EXHAUSTED")) {
      // Return a specific flag string that UI can detect
      throw new Error("QUOTA_EXCEEDED");
  }
  throw new Error(`L·ªói k·∫øt n·ªëi AI: ${cleanMsg}`);
}

// --- INTELLIGENT CONTEXT FILTERING ---
function filterRelevantContent(content: string, topic: string, limit: number): string {
    if (!topic || topic.trim().length < 2) {
        return content.substring(0, limit); 
    }

    const keywords = topic.toLowerCase().split(/\s+/).filter(w => w.length > 2); 
    if (keywords.length === 0) return content.substring(0, limit);

    const chunks = content.split(/\n\s*\n/); 
    
    const scoredChunks = chunks.map(chunk => {
        const lowerChunk = chunk.toLowerCase();
        let score = 0;
        keywords.forEach(kw => {
            if (lowerChunk.includes(kw)) score += 3; 
        });
        if (score > 0 && (lowerChunk.includes("kh√°i ni·ªám") || lowerChunk.includes("ƒë·ªãnh nghƒ©a") || lowerChunk.includes("ch·ª©c nƒÉng"))) {
            score += 1;
        }
        return { text: chunk, score };
    });

    scoredChunks.sort((a, b) => b.score - a.score);

    let result = "";
    let currentLen = 0;

    for (const chunk of scoredChunks) {
        if (chunk.score === 0 && currentLen > limit / 2) continue; 
        if (currentLen + chunk.text.length > limit) break;
        
        result += chunk.text + "\n\n";
        currentLen += chunk.text.length;
    }

    if (currentLen < Math.min(limit, 5000)) {
        const remaining = limit - currentLen;
        result += "\n--- Additional Context ---\n" + content.substring(0, remaining);
    }

    return result;
}

export const generateMCQQuestions = async (
  topic: string,
  count: number,
  difficulties: Difficulty[],
  files: { theory?: ContentFile[]; clinical?: ContentFile[]; sample?: ContentFile[] } = {}
): Promise<GeneratedMCQResponse> => {
  const ai = getAI();

  let systemInstruction = `
    B·∫°n l√† Gi√°o s∆∞ GI·∫¢I PH·∫™U ƒê·∫†I TH·ªÇ (Gross Anatomy) h√†ng ƒë·∫ßu t·∫°i ƒê·∫°i h·ªçc Y D∆∞·ª£c.
    Nhi·ªám v·ª•: T·∫°o ${count} c√¢u tr·∫Øc nghi·ªám gi·∫£i ph·∫´u v·ªÅ ch·ªß ƒë·ªÅ "${topic}".
    ƒê·ªô kh√≥: ${difficulties.join(', ')}.

    QUY T·∫ÆC T·ªêI TH∆Ø·ª¢NG (STRICT RULES):
    1. **TR·ªåNG T√ÇM L√Ä GI·∫¢I PH·∫™U ƒê·∫†I TH·ªÇ**:
       - Ch·ªâ t·∫≠p trung v√†o c·∫•u tr√∫c nh√¨n th·∫•y b·∫±ng m·∫Øt th∆∞·ªùng: C∆°, X∆∞∆°ng, Kh·ªõp, M·∫°ch m√°u, Th·∫ßn kinh, T·∫°ng, Li√™n quan gi·∫£i ph·∫´u.
       - H·ªèi v·ªÅ: Nguy√™n ·ªßy, B√°m t·∫≠n, ƒê∆∞·ªùng ƒëi, Chi ph·ªëi, C·∫•p m√°u, V·ªã tr√≠ t∆∞∆°ng ƒë·ªëi.
    
    2. **LO·∫†I B·ªé M√î H·ªåC/VI TH·ªÇ**:
       - TUY·ªÜT ƒê·ªêI KH√îNG h·ªèi v·ªÅ c·∫•u tr√∫c t·∫ø b√†o, m√¥ h·ªçc, k√≠nh hi·ªÉn vi (VD: bi·ªÉu m√¥ l√°t t·∫ßng, ti·ªÉu c·∫ßu th·∫≠n, t·∫ø b√†o gan...) tr·ª´ khi trong t√†i li·ªáu CH·ªà C√ì th√¥ng tin ƒë√≥.
       - N·∫øu t√†i li·ªáu ch·ª©a c·∫£ ƒê·∫°i th·ªÉ v√† Vi th·ªÉ, h√£y L·ªåC B·ªé Vi th·ªÉ v√† ch·ªâ l·∫•y ƒê·∫°i th·ªÉ.

    3. **B√ÅM S√ÅT T√ÄI LI·ªÜU**:
       - Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ vƒÉn b·∫£n ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi ƒë√¢y.
       - N·∫øu t√†i li·ªáu kh√¥ng c√≥ th√¥ng tin v·ªÅ "${topic}", h√£y tr·∫£ l·ªùi trung th·ª±c ho·∫∑c t·∫°o c√¢u h·ªèi t·ª´ ph·∫ßn c√≥ li√™n quan nh·∫•t trong t√†i li·ªáu ƒë√≥.

    4. **ƒê·ªäNH D·∫†NG JSON**:
       - Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng JSON thu·∫ßn t√∫y.
       - 4 l·ª±a ch·ªçn, 1 ƒë√°p √°n ƒë√∫ng.
       - Gi·∫£i th√≠ch ng·∫Øn g·ªçn, s√∫c t√≠ch, t·∫≠p trung v√†o t∆∞ duy gi·∫£i ph·∫´u.
  `;

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      questions: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            question: { type: Type.STRING },
            options: { type: Type.ARRAY, items: { type: Type.STRING } },
            correctAnswer: { type: Type.STRING },
            explanation: { type: Type.STRING },
            difficulty: { type: Type.STRING },
          },
          required: ["question", "options", "correctAnswer", "explanation", "difficulty"],
        },
      },
    },
    required: ["questions"],
  };

  const parts: any[] = [];

  const addContentParts = (fileItems: ContentFile[] | undefined, sectionTitle: string, charLimit: number) => {
    if (!fileItems || fileItems.length === 0) return;

    parts.push({ text: `\n--- T√ÄI LI·ªÜU ${sectionTitle} (ƒê√£ l·ªçc theo ch·ªß ƒë·ªÅ "${topic}") ---\n` });
    
    let currentChars = 0;

    for (const item of fileItems) {
        if (currentChars >= charLimit) break;

        if (item.content && item.isText) {
             const remaining = charLimit - currentChars;
             const relevantContent = filterRelevantContent(item.content, topic, remaining);
             
             parts.push({ text: relevantContent });
             currentChars += relevantContent.length;
        } else if (item.content && !item.isText) {
             parts.push({ text: item.content.substring(0, 1000) });
        }
    }
  };

  addContentParts(files.theory, "L√ù THUY·∫æT", LIMIT_THEORY_CHARS);
  addContentParts(files.clinical, "L√ÇM S√ÄNG", LIMIT_CLINICAL_CHARS);
  addContentParts(files.sample, "ƒê·ªÄ M·∫™U", LIMIT_SAMPLE_CHARS);

  parts.push({ text: `H√£y t·∫°o ƒë√∫ng ${count} c√¢u h·ªèi JSON v·ªÅ GI·∫¢I PH·∫™U ƒê·∫†I TH·ªÇ.` });

  return retryGeminiCall(async () => {
      const response = await ai.models.generateContent({
          model: MODEL_MCQ,
          contents: {
              role: 'user',
              parts: parts
          },
          config: {
              systemInstruction: systemInstruction,
              responseMimeType: "application/json",
              responseSchema: schema,
              temperature: 0.5 // Lower temperature for stricter adherence to facts
          }
      });

      const text = response.text;
      if (!text) throw new Error("AI tr·∫£ v·ªÅ d·ªØ li·ªáu r·ªóng.");
      return JSON.parse(text) as GeneratedMCQResponse;
  });
};

export const generateStationQuestionFromImage = async (
    base64Image: string,
    answerImageBase64: string | null,
    topic: string,
    detailedTopic: string = ""
): Promise<{ questions: any[], isValid: boolean }> => {
    const ai = getAI();

    // Extract clean base64
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "");
    const cleanAnswerBase64 = answerImageBase64 ? answerImageBase64.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "") : null;

    const systemInstruction = `
        B·∫°n l√† Tr∆∞·ªüng tr·∫°m thi Ch·∫°y tr·∫°m Gi·∫£i ph·∫´u (Spot Test) c·ª±c k·ª≥ nghi√™m kh·∫Øc.
        
        NHI·ªÜM V·ª§:
        B·∫°n s·∫Ω nh·∫≠n ƒë∆∞·ª£c 2 h√¨nh ·∫£nh:
        1. **H√åNH C√ÇU H·ªéI**: H√¨nh gi·∫£i ph·∫´u c√≥ c√°c ƒë∆∞·ªùng ch·ªâ d·∫´n ƒë√°nh s·ªë (1, 2, 3...).
        2. **H√åNH ƒê√ÅP √ÅN (Context)**: Trang s√°ch li·ªÅn sau, ch·ª©a ƒë√°p √°n (Ch√∫ th√≠ch) cho c√°c s·ªë tr√™n.

        Y√äU C·∫¶U X·ª¨ L√ù NGHI√äM NG·∫∂T (STRICT LOGIC):
        
        1. **B·ªò L·ªåC H√åNH ·∫¢NH (Image Filtering)**:
           - N·∫øu "H√åNH C√ÇU H·ªéI" ch·ª©a to√†n ch·ªØ (Text-only) ho·∫∑c KH√îNG C√ì H√åNH C·∫§U TR√öC GI·∫¢I PH·∫™U => Tr·∫£ v·ªÅ isValid: false.
           - N·∫øu "H√åNH C√ÇU H·ªéI" **KH√îNG C√ì** c√°c s·ªë ch√∫ th√≠ch (1, 2, 3...) ho·∫∑c ƒë∆∞·ªùng ch·ªâ d·∫´n => Tr·∫£ v·ªÅ isValid: false.
           - **QUAN TR·ªåNG: KI·ªÇM TRA CH·ª¶ ƒê·ªÄ**: N·∫øu h√¨nh ·∫£nh m√¥ t·∫£ c∆° quan/b·ªô ph·∫≠n KH√îNG LI√äN QUAN ƒë·∫øn "${detailedTopic || topic}" => Tr·∫£ v·ªÅ isValid: false.
             (V√≠ d·ª•: Ng∆∞·ªùi d√πng ch·ªçn ch·ªß ƒë·ªÅ "Tim", nh∆∞ng h√¨nh ·∫£nh l√† "Ph·ªïi", "D·∫° d√†y" ho·∫∑c "X∆∞∆°ng chi tr√™n" -> LO·∫†I NGAY L·∫¨P T·ª®C).

        2. **TR√çCH XU·∫§T ƒê√ÅP √ÅN T·ª™ H√åNH TH·ª® 2 (Contextual Extraction)**:
           - Ch·ªçn NG·∫™U NHI√äN 1 con s·ªë c√≥ tr√™n "H√åNH C√ÇU H·ªéI".
           - T√¨m s·ªë ƒë√≥ trong vƒÉn b·∫£n c·ªßa "H√åNH ƒê√ÅP √ÅN" ƒë·ªÉ l·∫•y t√™n c·∫•u tr√∫c ch√≠nh x√°c.
           - **TUY·ªÜT ƒê·ªêI KH√îNG B·ªäA ƒê·∫∂T**. ƒê√°p √°n (correctAnswer) PH·∫¢I l√† vƒÉn b·∫£n ch√≠nh x√°c n·∫±m trong "H√åNH ƒê√ÅP √ÅN" t∆∞∆°ng ·ª©ng v·ªõi s·ªë ƒë√£ ch·ªçn.

        3. **ƒê√ÅP √ÅN LINH HO·∫†T (Flexible Answers)**:
           - Trong danh s√°ch "acceptedKeywords", h√£y li·ªát k√™: 
             - T√™n ch√≠nh x√°c trong s√°ch.
             - T√™n Latin/Ti·∫øng Anh (n·∫øu c√≥ trong h√¨nh ƒë√°p √°n).
             - T√™n ti·∫øng Vi·ªát ƒë·ªìng nghƒ©a th√¥ng d·ª•ng.
             - C√°c t·ª´ vi·∫øt t·∫Øt y khoa ph·ªï bi·∫øn (ƒêM, TM, TK...).

        OUTPUT JSON:
        {
            "isValid": boolean, // false n·∫øu vi ph·∫°m b·ªô l·ªçc (sai ch·ªß ƒë·ªÅ, kh√¥ng c√≥ s·ªë, to√†n ch·ªØ)
            "questions": [
                {
                    "questionText": "Chi ti·∫øt s·ªë [X] l√† g√¨?",
                    "correctAnswer": "T√™n ch√≠nh x√°c tr√≠ch t·ª´ H√åNH ƒê√ÅP √ÅN",
                    "acceptedKeywords": ["t√™n 1", "t√™n 2", "t√™n latin", "vi·∫øt t·∫Øt"],
                    "explanation": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn ch·ª©c nƒÉng/v·ªã tr√≠ d·ª±a tr√™n h√¨nh ·∫£nh."
                }
            ]
        }
    `;

    const schema: Schema = {
        type: Type.OBJECT,
        properties: {
            isValid: { type: Type.BOOLEAN },
            questions: {
                type: Type.ARRAY,
                items: {
                    type: Type.OBJECT,
                    properties: {
                        questionText: { type: Type.STRING },
                        correctAnswer: { type: Type.STRING },
                        acceptedKeywords: { 
                            type: Type.ARRAY, 
                            items: { type: Type.STRING }
                        },
                        explanation: { type: Type.STRING }
                    },
                    required: ["questionText", "correctAnswer", "acceptedKeywords", "explanation"]
                }
            }
        },
        required: ["isValid", "questions"]
    };

    const parts: any[] = [];
    
    // 1. Add Question Image
    parts.push({ inlineData: { mimeType: 'image/jpeg', data: cleanBase64 } });
    
    // 2. Add Answer Image if available
    if (cleanAnswerBase64) {
        parts.push({ inlineData: { mimeType: 'image/jpeg', data: cleanAnswerBase64 } });
        parts.push({ text: `H√åNH 1 l√† C√ÇU H·ªéI (c·∫•u tr√∫c c√≥ s·ªë). H√åNH 2 l√† ƒê√ÅP √ÅN (vƒÉn b·∫£n gi·∫£i th√≠ch s·ªë). H√£y t√¨m ƒë√°p √°n ƒë√∫ng t·ª´ H√åNH 2 cho m·ªôt s·ªë b·∫•t k·ª≥ tr√™n H√åNH 1. Ch·ªß ƒë·ªÅ B·∫ÆT BU·ªòC ph·∫£i l√†: "${detailedTopic}".` });
    } else {
        parts.push({ text: `H√£y ph√¢n t√≠ch h√¨nh ·∫£nh gi·∫£i ph·∫´u n√†y. Ch·ªß ƒë·ªÅ b·∫Øt bu·ªôc: ${detailedTopic}.` });
    }

    return retryGeminiCall(async () => {
        const response = await ai.models.generateContent({
            model: MODEL_VISION,
            contents: {
                role: 'user',
                parts: parts
            },
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: schema,
                temperature: 0.1 // Very low temperature for precise extraction
            }
        });
        
        const text = response.text;
        if (!text) return { questions: [], isValid: false };
        return JSON.parse(text);
    });
};

export const chatWithOtter = async (history: any[], newMessage: string, image?: string): Promise<string> => {
    const ai = getAI();

    let parts: any[] = [];
    if (image) {
        const cleanBase64 = image.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "");
        parts.push({ inlineData: { mimeType: 'image/jpeg', data: cleanBase64 } });
    }
    parts.push({ text: newMessage });

    const recentHistory = history.slice(-8).map(h => ({
        role: h.role === 'model' ? 'model' : 'user',
        parts: [{ text: h.text }] 
    }));

    return retryGeminiCall(async () => {
        const chat = ai.chats.create({
            model: MODEL_CHAT,
            history: recentHistory,
            config: {
                systemInstruction: "B·∫°n l√† R√°i C√° Anatomy, tr·ª£ l√Ω h·ªçc t·∫≠p vui v·∫ª, chuy√™n gia gi·∫£i ph·∫´u h·ªçc.",
            }
        });

        const result = await chat.sendMessage({
            parts: parts
        });

        return result.text || "R√°i c√° ƒëang b·∫≠n b·∫Øt c√°, th·ª≠ l·∫°i sau nh√©! ü¶¶";
    });
};

export const analyzeResultWithOtter = async (topic: string, stats: any): Promise<MentorResponse> => {
    const ai = getAI();
    
    // UPGRADED SYSTEM INSTRUCTION FOR DEEP ANALYSIS
    const systemInstruction = `
        B·∫°n l√† R√°i C√° Mentor - m·ªôt Gi√°o s∆∞ Gi·∫£i ph·∫´u h·ªçc h√†ng ƒë·∫ßu, r·∫•t nghi√™m kh·∫Øc v·ªÅ chuy√™n m√¥n nh∆∞ng c≈©ng vui t√≠nh (d√πng emoji ü¶¶, üß†, ü¶¥).
        
        Nhi·ªám v·ª•: Ph√¢n t√≠ch k·∫øt qu·∫£ b√†i thi c·ªßa sinh vi√™n y khoa m·ªôt c√°ch chuy√™n s√¢u (Deep Dive Analysis).
        
        D·ªØ li·ªáu ƒë·∫ßu v√†o:
        - Ch·ªß ƒë·ªÅ: ${topic}
        - S·ªë li·ªáu: ${JSON.stringify(stats)} (S·ªë c√¢u ƒë√∫ng/t·ªïng theo t·ª´ng m·ª©c ƒë·ªô kh√≥).

        Y√™u c·∫ßu output (JSON):
        1. "analysis": M·ªôt ƒëo·∫°n vƒÉn ng·∫Øn (3-4 c√¢u) nh·∫≠n x√©t t·ªïng quan. H√£y so s√°nh kh·∫£ nƒÉng ghi nh·ªõ (L√Ω thuy·∫øt) v·ªõi kh·∫£ nƒÉng v·∫≠n d·ª•ng (L√¢m s√†ng). N·∫øu l√†m sai c√¢u l√¢m s√†ng, h√£y nh·∫Øc nh·ªü v·ªÅ t·∫ßm quan tr·ªçng c·ªßa vi·ªác ·ª©ng d·ª•ng. N·∫øu sai c√¢u c∆° b·∫£n, h√£y nh·∫Øc h·ªçc l·∫°i gi·∫£i ph·∫´u ƒë·∫°i th·ªÉ.
        2. "strengths": Li·ªát k√™ 2-3 ƒëi·ªÉm m·∫°nh c·ª• th·ªÉ d·ª±a tr√™n s·ªë li·ªáu (VD: "T∆∞ duy l√¢m s√†ng s·∫Øc b√©n", "N·∫Øm v·ªØng chi ti·∫øt gi·∫£i ph·∫´u h·ªçc").
        3. "weaknesses": Li·ªát k√™ 2-3 ƒëi·ªÉm y·∫øu ch√≠ m·∫°ng c·∫ßn kh·∫Øc ph·ª•c ngay (VD: "H·ªïng ki·∫øn th·ª©c gi·∫£i ph·∫´u ƒë·ªãnh khu", "Ch∆∞a li√™n k·∫øt ƒë∆∞·ª£c gi·∫£i ph·∫´u v√† tri·ªáu ch·ª©ng").
        4. "roadmap": ƒê∆∞a ra m·ªôt l·ªô tr√¨nh 3 b∆∞·ªõc (Step 1, Step 2, Step 3) c·ª±c k·ª≥ c·ª• th·ªÉ ƒë·ªÉ c·∫£i thi·ªán ch·ªß ƒë·ªÅ n√†y. 
           - Step 1: T·∫≠p trung v√†o t√†i li·ªáu n√†o, ph∆∞∆°ng ph√°p n√†o (Atlas Netter, Flashcard...).
           - Step 2: C√°ch t∆∞ duy (Li√™n h·ªá ch·ª©c nƒÉng, v·∫Ω s∆° ƒë·ªì t∆∞ duy...).
           - Step 3: Luy·ªán t·∫≠p n√¢ng cao (Gi·∫£i case study, ch·∫°y tr·∫°m...).
    `;

    const schema: Schema = {
        type: Type.OBJECT,
        properties: {
            analysis: { type: Type.STRING, description: "Nh·∫≠n x√©t chuy√™n s√¢u, so s√°nh l√Ω thuy·∫øt v√† l√¢m s√†ng." },
            strengths: { type: Type.ARRAY, items: { type: Type.STRING } },
            weaknesses: { type: Type.ARRAY, items: { type: Type.STRING } },
            roadmap: {
                type: Type.ARRAY,
                items: {
                    type: Type.OBJECT,
                    properties: {
                        step: { type: Type.STRING, description: "T√™n b∆∞·ªõc (VD: B∆∞·ªõc 1: C·ªßng c·ªë n·ªÅn t·∫£ng)" },
                        details: { type: Type.STRING, description: "Chi ti·∫øt h√†nh ƒë·ªông c·∫ßn l√†m" }
                    },
                    required: ["step", "details"]
                }
            }
        },
        required: ["analysis", "strengths", "weaknesses", "roadmap"]
    };

    return retryGeminiCall(async () => {
        const response = await ai.models.generateContent({
            model: MODEL_MCQ, 
            contents: {
                role: 'user',
                parts: [{ text: `Ph√¢n t√≠ch k·∫øt qu·∫£ b√†i thi ch·ªß ƒë·ªÅ "${topic}". S·ªë li·ªáu chi ti·∫øt: ${JSON.stringify(stats)}.` }]
            },
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: schema,
                temperature: 0.7 // Increase slightly for more creative advice
            }
        });

        const text = response.text;
        if (!text) throw new Error("No analysis");
        return JSON.parse(text) as MentorResponse;
    });
};
