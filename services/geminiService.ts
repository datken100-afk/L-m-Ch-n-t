
import { GoogleGenAI, Type, Schema, GenerateContentResponse } from "@google/genai";
import { Difficulty, GeneratedMCQResponse, GeneratedStationResponse, MentorResponse, StationItem } from "../types";

// Storage Key for User's Custom API Key
export const STORAGE_API_KEY = 'OTTER_API_KEY';

// Helper to get the active client instance dynamically
const getAI = () => {
    const customKey = localStorage.getItem(STORAGE_API_KEY);
    // Prioritize custom key, fallback to env
    const key = customKey && customKey.trim().length > 0 ? customKey : (process.env.API_KEY || '');
    
    if (!key) {
        // Throw a specific error that UI can catch to show the Key Modal
        throw new Error("MISSING_API_KEY"); 
    }
    return new GoogleGenAI({ apiKey: key });
};

// OPTIMIZATION: Use Gemini 2.5 Flash exclusively.
const MODEL_MCQ = "gemini-2.5-flash"; 
const MODEL_VISION = "gemini-2.5-flash"; 
const MODEL_CHAT = "gemini-2.5-flash";

interface ContentFile {
    content: string;
    isText: boolean;
}

// OPTIMIZATION: Massive Token Limits for Gemini 2.5 Flash (1M context)
// We can afford to send much more context to ensure accuracy.
const LIMIT_THEORY_CHARS = 200000; 
const LIMIT_CLINICAL_CHARS = 100000; 
const LIMIT_SAMPLE_CHARS = 50000;

// --- RETRY LOGIC HELPER ---
const wait = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

async function retryGeminiCall<T>(
  call: () => Promise<T>,
  retries: number = 3,
  initialDelay: number = 2000
): Promise<T> {
  let lastError: any;
  
  for (let i = 0; i < retries; i++) {
    try {
      return await call();
    } catch (error: any) {
      lastError = error;
      
      const isRateLimit = 
        error.status === 429 || 
        error.status === 503 ||
        (error.message && (
          error.message.includes("429") || 
          error.message.includes("quota") || 
          error.message.includes("RESOURCE_EXHAUSTED") ||
          error.message.includes("Overloaded")
        ));

      if (error.status === 404 || (error.message && error.message.includes("not found"))) {
          throw new Error(`L·ªói Model AI (${error.status}): Kh√¥ng t√¨m th·∫•y Model. Vui l√≤ng Redeploy code m·ªõi nh·∫•t.`);
      }
      
      // Invalid Key Error
      if (error.status === 400 && error.message?.includes("API key")) {
          throw new Error("INVALID_API_KEY");
      }

      if (isRateLimit) {
        if (i === retries - 1) break; 
        console.warn(`Gemini Rate Limit hit. Retrying in ${initialDelay}ms... (Attempt ${i + 1}/${retries})`);
        await wait(initialDelay);
        initialDelay *= 2; 
      } else {
        throw error; 
      }
    }
  }
  
  const cleanMsg = lastError?.message || "Unknown error";
  if (cleanMsg.includes("quota") || cleanMsg.includes("RESOURCE_EXHAUSTED")) {
      // Return a specific flag string that UI can detect
      throw new Error("QUOTA_EXCEEDED");
  }
  throw new Error(`L·ªói k·∫øt n·ªëi AI: ${cleanMsg}`);
}

// --- INTELLIGENT CONTEXT FILTERING (RELAXED) ---
// With larger context window, we can be less aggressive about filtering.
function filterRelevantContent(content: string, topic: string, limit: number): string {
    if (!topic || topic.trim().length < 2) {
        return content.substring(0, limit); 
    }

    const keywords = topic.toLowerCase().split(/\s+/).filter(w => w.length > 2); 
    if (keywords.length === 0) return content.substring(0, limit);

    // Split by paragraphs to keep context together
    const chunks = content.split(/\n\s*\n/); 
    
    const scoredChunks = chunks.map(chunk => {
        const lowerChunk = chunk.toLowerCase();
        let score = 0;
        // Base score for keyword match
        keywords.forEach(kw => {
            if (lowerChunk.includes(kw)) score += 5; 
        });
        // Boost for definition/intro
        if (score > 0 && (lowerChunk.includes("kh√°i ni·ªám") || lowerChunk.includes("ƒë·ªãnh nghƒ©a") || lowerChunk.includes("ch·ª©c nƒÉng") || lowerChunk.includes("c·∫•u t·∫°o"))) {
            score += 2;
        }
        // Boost for exact phrase match (high value)
        if (lowerChunk.includes(topic.toLowerCase())) {
            score += 10;
        }
        return { text: chunk, score };
    });

    // Sort by score descending
    scoredChunks.sort((a, b) => b.score - a.score);

    let result = "";
    let currentLen = 0;

    for (const chunk of scoredChunks) {
        // Include chunk if it has a score OR if we have plenty of space (context filler)
        // But prioritize high scores first.
        if (chunk.score === 0 && currentLen > limit * 0.8) continue; 
        
        if (currentLen + chunk.text.length > limit) break;
        
        result += chunk.text + "\n\n";
        currentLen += chunk.text.length;
    }

    return result;
}

export const generateMCQQuestions = async (
  topic: string,
  count: number,
  difficulties: Difficulty[],
  files: { theory?: ContentFile[]; clinical?: ContentFile[]; sample?: ContentFile[] } = {}
): Promise<GeneratedMCQResponse> => {
  const ai = getAI();

  // REFINED PROMPT FOR STRICTER TOPIC ADHERENCE AND DIFFICULTY ANALYSIS
  let systemInstruction = `
    B·∫°n l√† Gi√°o s∆∞ GI·∫¢I PH·∫™U ƒê·∫†I TH·ªÇ (Gross Anatomy) h√†ng ƒë·∫ßu t·∫°i ƒê·∫°i h·ªçc Y D∆∞·ª£c.
    Nhi·ªám v·ª•: Ph√¢n t√≠ch K·ª∏ L∆Ø·ª†NG t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p (n·∫øu c√≥) ƒë·ªÉ t·∫°o CH√çNH X√ÅC ${count} c√¢u tr·∫Øc nghi·ªám.
    Ch·ªß ƒë·ªÅ Tr·ªçng T√¢m: "${topic}".
    
    Y√äU C·∫¶U V·ªÄ ƒê·ªò KH√ì (B·∫ÆT BU·ªòC TU√ÇN TH·ª¶):
    B·∫°n ch·ªâ ƒë∆∞·ª£c t·∫°o c√¢u h·ªèi thu·ªôc c√°c m·ª©c ƒë·ªô sau: ${difficulties.join(', ')}. H√£y chia t·ª∑ l·ªá h·ª£p l√Ω.
    
    CHI·∫æN L∆Ø·ª¢C PH√ÇN T√çCH FILE & T·∫†O C√ÇU H·ªéI:
    
    1. **${Difficulty.REMEMBER} (Ghi nh·ªõ)**: 
       - Qu√©t file L√ù THUY·∫æT: T√¨m c√°c ƒë·ªãnh nghƒ©a, t√™n c·∫•u tr√∫c, nguy√™n ·ªßy, b√°m t·∫≠n, chi ph·ªëi th·∫ßn kinh.
       - H·ªèi tr·ª±c di·ªán: "C∆° n√†o...", "Th·∫ßn kinh n√†o...", "C·∫•u tr√∫c n√†o n·∫±m ·ªü...".
       
    2. **${Difficulty.UNDERSTAND} (Hi·ªÉu)**: 
       - Qu√©t file L√ù THUY·∫æT: T√¨m c√°c ƒëo·∫°n vƒÉn m√¥ t·∫£ li√™n quan, ch·ª©c nƒÉng, s·ª± t∆∞∆°ng quan gi·ªØa c√°c c∆° quan.
       - H·ªèi v·ªÅ c∆° ch·∫ø: "T·∫°i sao...", "Ch·ª©c nƒÉng ch√≠nh c·ªßa...", "H·ªá qu·∫£ khi...".
       
    3. **${Difficulty.APPLY} (V·∫≠n d·ª•ng th·∫•p)**: 
       - K·∫øt h·ª£p th√¥ng tin L√ù THUY·∫æT: ƒê·∫∑t t√¨nh hu·ªëng gi·∫£ ƒë·ªãnh ƒë∆°n gi·∫£n v·ªÅ v·ªã tr√≠ t∆∞∆°ng ƒë·ªëi.
       - V√≠ d·ª•: "Trong ph·∫´u thu·∫≠t v√πng X, c·∫•u tr√∫c n√†o d·ªÖ b·ªã t·ªïn th∆∞∆°ng nh·∫•t?".
       
    4. **${Difficulty.CLINICAL} (L√¢m s√†ng)**: 
       - **QUAN TR·ªåNG**: ∆Øu ti√™n t·ªëi ƒëa vi·ªác tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ file "L√ÇM S√ÄNG" (Case Study, B·ªánh √°n) n·∫øu ng∆∞·ªùi d√πng cung c·∫•p.
       - N·∫øu c√≥ file L√¢m s√†ng: H√£y t·∫°o c√¢u h·ªèi d·ª±a tr√™n ƒë√∫ng c√°c case ƒë√≥.
       - N·∫øu KH√îNG c√≥ file L√¢m s√†ng: H√£y d√πng ki·∫øn th·ª©c y khoa chu·∫©n ƒë·ªÉ t·∫°o t√¨nh hu·ªëng b·ªánh l√Ω th·ª±c t·∫ø li√™n quan ƒë·∫øn "${topic}" (G√£y x∆∞∆°ng, li·ªát th·∫ßn kinh, t·∫Øc m·∫°ch...).
       - C·∫•u tr√∫c: [M√¥ t·∫£ tri·ªáu ch·ª©ng/Ti·ªÅn s·ª≠] -> [H·ªèi v·ªÅ t·ªïn th∆∞∆°ng gi·∫£i ph·∫´u].

    QUY T·∫ÆC CHUNG:
    - **B√ÅM S√ÅT FILE**: N·∫øu t√†i li·ªáu c√≥ th√¥ng tin v·ªÅ "${topic}", ph·∫£i ∆∞u ti√™n d√πng n√≥ l√†m d·ªØ li·ªáu ngu·ªìn (grounding).
    - **GROSS ANATOMY ONLY**: Ch·ªâ h·ªèi gi·∫£i ph·∫´u ƒë·∫°i th·ªÉ (C∆°, X∆∞∆°ng, M·∫°ch, Th·∫ßn kinh, T·∫°ng). Kh√¥ng h·ªèi m√¥ h·ªçc/t·∫ø b√†o.
    - **OUTPUT**: JSON thu·∫ßn t√∫y.
  `;

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      questions: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            question: { type: Type.STRING },
            options: { type: Type.ARRAY, items: { type: Type.STRING } },
            correctAnswer: { type: Type.STRING },
            explanation: { type: Type.STRING },
            difficulty: { type: Type.STRING },
          },
          required: ["question", "options", "correctAnswer", "explanation", "difficulty"],
        },
      },
    },
    required: ["questions"],
  };

  const parts: any[] = [];

  const addContentParts = (fileItems: ContentFile[] | undefined, sectionTitle: string, charLimit: number) => {
    if (!fileItems || fileItems.length === 0) return;

    parts.push({ text: `\n--- T√ÄI LI·ªÜU THAM KH·∫¢O: ${sectionTitle} ---\n` });
    
    let currentChars = 0;

    for (const item of fileItems) {
        if (currentChars >= charLimit) break;

        if (item.content && item.isText) {
             const remaining = charLimit - currentChars;
             // Filter content to prioritize the topic, but keep large context
             const relevantContent = filterRelevantContent(item.content, topic, remaining);
             
             parts.push({ text: relevantContent });
             currentChars += relevantContent.length;
        } else if (item.content && !item.isText) {
             parts.push({ text: item.content.substring(0, 2000) });
        }
    }
  };

  addContentParts(files.theory, "L√ù THUY·∫æT", LIMIT_THEORY_CHARS);
  addContentParts(files.clinical, "L√ÇM S√ÄNG (D√πng cho c√¢u h·ªèi L√¢m s√†ng)", LIMIT_CLINICAL_CHARS);
  addContentParts(files.sample, "ƒê·ªÄ M·∫™U", LIMIT_SAMPLE_CHARS);

  // Final Reminder in prompt
  parts.push({ text: `Y√äU C·∫¶U: T·∫°o ${count} c√¢u h·ªèi tr·∫Øc nghi·ªám v·ªÅ ch·ªß ƒë·ªÅ "${topic}". H√£y ph√¢n t√≠ch k·ªπ c√°c file tr√™n (ƒë·∫∑c bi·ªát l√† file L√¢m s√†ng cho c√¢u h·ªèi L√¢m s√†ng) ƒë·ªÉ t·∫°o c√¢u h·ªèi s√°t th·ª±c t·∫ø.` });

  return retryGeminiCall(async () => {
      const response = await ai.models.generateContent({
          model: MODEL_MCQ,
          contents: [{
              role: 'user',
              parts: parts
          }],
          config: {
              systemInstruction: systemInstruction,
              responseMimeType: "application/json",
              responseSchema: schema,
              temperature: 0.4
          }
      });

      const text = response.text;
      if (!text) throw new Error("AI tr·∫£ v·ªÅ d·ªØ li·ªáu r·ªóng.");
      return JSON.parse(text) as GeneratedMCQResponse;
  });
};

export const generateStationQuestionFromImage = async (
    base64Image: string,
    answerImageBase64: string | null,
    topic: string,
    detailedTopic: string = ""
): Promise<{ questions: any[], isValid: boolean }> => {
    const ai = getAI();

    // Extract clean base64
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "");
    const cleanAnswerBase64 = answerImageBase64 ? answerImageBase64.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "") : null;

    // STRICTER SYSTEM INSTRUCTION
    const systemInstruction = `
        B·∫°n l√† H·ªôi ƒë·ªìng Kh·∫£o th√≠ Gi·∫£i ph·∫´u h·ªçc c·ª±c k·ª≥ nghi√™m ng·∫∑t.
        Nhi·ªám v·ª•: Ki·ªÉm duy·ªát h√¨nh ·∫£nh v√† t·∫°o 1 c√¢u h·ªèi ƒë·ªãnh danh c·∫•u tr√∫c (Spot Test) N·∫æU V√Ä CH·ªà N·∫æU h√¨nh ·∫£nh ƒë·∫°t chu·∫©n.

        D·ªÆ LI·ªÜU:
        - H√åNH 1: ƒê·ªÅ b√†i (Th∆∞·ªùng l√† h√¨nh v·∫Ω gi·∫£i ph·∫´u).
        - H√åNH 2: ƒê√°p √°n/Ch√∫ th√≠ch (N·∫øu c√≥).
        - CH·ª¶ ƒê·ªÄ Y√äU C·∫¶U: "${detailedTopic}".

        QUY TR√åNH KI·ªÇM DUY·ªÜT (STEP-BY-STEP):
        
        1. **B∆Ø·ªöC 1: KI·ªÇM TRA LO·∫†I H√åNH ·∫¢NH (Quan tr·ªçng nh·∫•t)**
           - Nh√¨n v√†o H√åNH 1.
           - N·∫øu H√åNH 1 ch·ª©a 80% l√† vƒÉn b·∫£n, danh s√°ch (list), b·∫£ng bi·ªÉu (table), ho·∫∑c m·ª•c l·ª•c -> **TR·∫¢ V·ªÄ isValid: false NGAY L·∫¨P T·ª®C**.
           - N·∫øu H√åNH 1 l√† trang tr·∫Øng ho·∫∑c ch·ªâ c√≥ ti√™u ƒë·ªÅ -> **TR·∫¢ V·ªÄ isValid: false**.
           - H√åNH 1 B·∫ÆT BU·ªòC ph·∫£i l√† H√åNH V·∫º MINH H·ªåA GI·∫¢I PH·∫™U (Atlas, m√¥ h√¨nh, x√°c, x∆∞∆°ng, c∆°...).

        2. **B∆Ø·ªöC 2: KI·ªÇM TRA CH·ª¶ ƒê·ªÄ**
           - H√¨nh ·∫£nh c√≥ li√™n quan ƒë·∫øn "${detailedTopic}" kh√¥ng?
           - V√≠ d·ª•: Y√™u c·∫ßu "Tim m·∫°ch" nh∆∞ng h√¨nh l√† "X∆∞∆°ng chi d∆∞·ªõi" -> **TR·∫¢ V·ªÄ isValid: false**.
           - Ch·ªâ ch·∫•p nh·∫≠n n·∫øu ƒë√∫ng ho·∫∑c li√™n quan m·∫≠t thi·∫øt ƒë·∫øn ch·ªß ƒë·ªÅ.

        3. **B∆Ø·ªöC 3: T·∫†O C√ÇU H·ªéI (Ch·ªâ khi B∆∞·ªõc 1 & 2 OK)**
           - T√¨m m·ªôt chi ti·∫øt c√≥ s·ªë ho·∫∑c m≈©i t√™n tr√™n H√åNH 1.
           - ƒê·ªëi chi·∫øu H√åNH 2 ƒë·ªÉ t√¨m t√™n ch√≠nh x√°c.
           - N·∫øu kh√¥ng c√≥ s·ªë: H√£y t·ª± ch·ªçn m·ªôt c·∫•u tr√∫c N·ªîI B·∫¨T NH·∫§T v√† h·ªèi.
           - Output c√¢u h·ªèi JSON.

        OUTPUT JSON:
        {
            "isValid": boolean, // False n·∫øu l√† trang ch·ªØ/m·ª•c l·ª•c/sai ch·ªß ƒë·ªÅ.
            "questions": [
                {
                    "questionText": "C·∫•u tr√∫c s·ªë X l√† g√¨?",
                    "correctAnswer": "T√™n chu·∫©n (Latin/Vi·ªát)",
                    "acceptedKeywords": ["t√™n kh√°c"],
                    "explanation": "M√¥ t·∫£ ng·∫Øn g·ªçn v·ªã tr√≠/ch·ª©c nƒÉng."
                }
            ]
        }
    `;

    const schema: Schema = {
        type: Type.OBJECT,
        properties: {
            isValid: { type: Type.BOOLEAN },
            questions: {
                type: Type.ARRAY,
                items: {
                    type: Type.OBJECT,
                    properties: {
                        questionText: { type: Type.STRING },
                        correctAnswer: { type: Type.STRING },
                        acceptedKeywords: { 
                            type: Type.ARRAY, 
                            items: { type: Type.STRING }
                        },
                        explanation: { type: Type.STRING }
                    },
                    required: ["questionText", "correctAnswer", "acceptedKeywords", "explanation"]
                }
            }
        },
        required: ["isValid", "questions"]
    };

    const parts: any[] = [];
    
    // 1. Add Question Image
    parts.push({ inlineData: { mimeType: 'image/jpeg', data: cleanBase64 } });
    
    // 2. Add Answer Image if available
    if (cleanAnswerBase64) {
        parts.push({ inlineData: { mimeType: 'image/jpeg', data: cleanAnswerBase64 } });
        parts.push({ text: `H√åNH 1 l√† C√ÇU H·ªéI. H√åNH 2 l√† ƒê√ÅP √ÅN. Ki·ªÉm tra k·ªπ xem H√åNH 1 c√≥ ph·∫£i l√† h√¨nh v·∫Ω gi·∫£i ph·∫´u kh√¥ng. N·∫øu to√†n ch·ªØ -> isValid: false.` });
    } else {
        parts.push({ text: `Ph√¢n t√≠ch h√¨nh ·∫£nh n√†y. N·∫øu l√† vƒÉn b·∫£n/text -> isValid: false.` });
    }

    return retryGeminiCall(async () => {
        const response = await ai.models.generateContent({
            model: MODEL_VISION,
            contents: [{
                role: 'user',
                parts: parts
            }],
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: schema,
                temperature: 0.2 // Low temperature to be strict about isValid rules
            }
        });
        
        const text = response.text;
        if (!text) return { questions: [], isValid: false };
        try {
            return JSON.parse(text);
        } catch (e) {
            // If JSON parsing fails, treat as invalid
            console.error("JSON Parse Error", text);
            return { questions: [], isValid: false };
        }
    });
};

export const chatWithOtter = async (history: any[], newMessage: string, image?: string): Promise<string> => {
    const ai = getAI();

    // Prepare conversation history for generateContent (Stateless usage)
    // history contains objects like { role: 'user'|'model', text: string }
    const contents: any[] = history.map(h => ({
        role: h.role === 'model' ? 'model' : 'user',
        parts: [{ text: h.text }] 
    }));

    // Prepare the new message parts
    const currentParts: any[] = [];
    if (image) {
        const cleanBase64 = image.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "");
        currentParts.push({ inlineData: { mimeType: 'image/jpeg', data: cleanBase64 } });
    }
    currentParts.push({ text: newMessage });

    // Add new message to the end of contents
    contents.push({
        role: 'user',
        parts: currentParts
    });

    return retryGeminiCall(async () => {
        // Use generateContent directly instead of chats.create/sendMessage to avoid ContentUnion/State errors
        const response = await ai.models.generateContent({
            model: MODEL_CHAT,
            contents: contents,
            config: {
                systemInstruction: "B·∫°n l√† R√°i C√° Anatomy, tr·ª£ l√Ω h·ªçc t·∫≠p vui v·∫ª, chuy√™n gia gi·∫£i ph·∫´u h·ªçc. H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch v√† d·ªÖ hi·ªÉu. S·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng Markdown (in ƒë·∫≠m, g·∫°ch ƒë·∫ßu d√≤ng) ƒë·ªÉ tr√¨nh b√†y r√µ r√†ng.",
            }
        });

        return response.text || "R√°i c√° ƒëang b·∫≠n b·∫Øt c√°, th·ª≠ l·∫°i sau nh√©! ü¶¶";
    });
};

export const analyzeResultWithOtter = async (topic: string, stats: any): Promise<MentorResponse> => {
    const ai = getAI();
    
    // UPGRADED SYSTEM INSTRUCTION FOR DEEP ANALYSIS
    const systemInstruction = `
        B·∫°n l√† R√°i C√° Mentor - m·ªôt Gi√°o s∆∞ Gi·∫£i ph·∫´u h·ªçc h√†ng ƒë·∫ßu, r·∫•t nghi√™m kh·∫Øc v·ªÅ chuy√™n m√¥n nh∆∞ng c≈©ng vui t√≠nh (d√πng emoji ü¶¶, üß†, ü¶¥).
        
        Nhi·ªám v·ª•: Ph√¢n t√≠ch k·∫øt qu·∫£ b√†i thi c·ªßa sinh vi√™n y khoa m·ªôt c√°ch chuy√™n s√¢u (Deep Dive Analysis).
        
        D·ªØ li·ªáu ƒë·∫ßu v√†o:
        - Ch·ªß ƒë·ªÅ: ${topic}
        - S·ªë li·ªáu: ${JSON.stringify(stats)} (S·ªë c√¢u ƒë√∫ng/t·ªïng theo t·ª´ng m·ª©c ƒë·ªô kh√≥).

        Y√™u c·∫ßu output (JSON):
        1. "analysis": M·ªôt ƒëo·∫°n vƒÉn ng·∫Øn (3-4 c√¢u) nh·∫≠n x√©t t·ªïng quan. H√£y so s√°nh kh·∫£ nƒÉng ghi nh·ªõ (L√Ω thuy·∫øt) v·ªõi kh·∫£ nƒÉng v·∫≠n d·ª•ng (L√¢m s√†ng). N·∫øu l√†m sai c√¢u l√¢m s√†ng, h√£y nh·∫Øc nh·ªü v·ªÅ t·∫ßm quan tr·ªçng c·ªßa vi·ªác ·ª©ng d·ª•ng. N·∫øu sai c√¢u c∆° b·∫£n, h√£y nh·∫Øc h·ªçc l·∫°i gi·∫£i ph·∫´u ƒë·∫°i th·ªÉ.
        2. "strengths": Li·ªát k√™ 2-3 ƒëi·ªÉm m·∫°nh c·ª• th·ªÉ d·ª±a tr√™n s·ªë li·ªáu (VD: "T∆∞ duy l√¢m s√†ng s·∫Øc b√©n", "N·∫Øm v·ªØng chi ti·∫øt gi·∫£i ph·∫´u h·ªçc").
        3. "weaknesses": Li·ªát k√™ 2-3 ƒëi·ªÉm y·∫øu ch√≠ m·∫°ng c·∫ßn kh·∫Øc ph·ª•c ngay (VD: "H·ªïng ki·∫øn th·ª©c gi·∫£i ph·∫´u ƒë·ªãnh khu", "Ch∆∞a li√™n k·∫øt ƒë∆∞·ª£c gi·∫£i ph·∫´u v√† tri·ªáu ch·ª©ng").
        4. "roadmap": ƒê∆∞a ra m·ªôt l·ªô tr√¨nh 3 b∆∞·ªõc (Step 1, Step 2, Step 3) c·ª±c k·ª≥ c·ª• th·ªÉ ƒë·ªÉ c·∫£i thi·ªán ch·ªß ƒë·ªÅ n√†y. 
           - Step 1: T·∫≠p trung v√†o t√†i li·ªáu n√†o, ph∆∞∆°ng ph√°p n√†o (Atlas Netter, Flashcard...).
           - Step 2: C√°ch t∆∞ duy (Li√™n h·ªá ch·ª©c nƒÉng, v·∫Ω s∆° ƒë·ªì t∆∞ duy...).
           - Step 3: Luy·ªán t·∫≠p n√¢ng cao (Gi·∫£i case study, ch·∫°y tr·∫°m...).
    `;

    const schema: Schema = {
        type: Type.OBJECT,
        properties: {
            analysis: { type: Type.STRING, description: "Nh·∫≠n x√©t chuy√™n s√¢u, so s√°nh l√Ω thuy·∫øt v√† l√¢m s√†ng." },
            strengths: { type: Type.ARRAY, items: { type: Type.STRING } },
            weaknesses: { type: Type.ARRAY, items: { type: Type.STRING } },
            roadmap: {
                type: Type.ARRAY,
                items: {
                    type: Type.OBJECT,
                    properties: {
                        step: { type: Type.STRING, description: "T√™n b∆∞·ªõc (VD: B∆∞·ªõc 1: C·ªßng c·ªë n·ªÅn t·∫£ng)" },
                        details: { type: Type.STRING, description: "Chi ti·∫øt h√†nh ƒë·ªông c·∫ßn l√†m" }
                    },
                    required: ["step", "details"]
                }
            }
        },
        required: ["analysis", "strengths", "weaknesses", "roadmap"]
    };

    return retryGeminiCall(async () => {
        const response = await ai.models.generateContent({
            model: MODEL_MCQ, 
            contents: [{
                role: 'user',
                parts: [{ text: `Ph√¢n t√≠ch k·∫øt qu·∫£ b√†i thi ch·ªß ƒë·ªÅ "${topic}". S·ªë li·ªáu chi ti·∫øt: ${JSON.stringify(stats)}.` }]
            }],
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: schema,
                temperature: 0.7 // Increase slightly for more creative advice
            }
        });

        const text = response.text;
        if (!text) throw new Error("No analysis");
        return JSON.parse(text) as MentorResponse;
    });
};
